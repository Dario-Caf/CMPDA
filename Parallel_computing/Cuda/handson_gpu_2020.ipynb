{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"handson_gpu_2020.ipynb","provenance":[],"collapsed_sections":["2fX5vZR51Lzf"],"toc_visible":true,"authorship_tag":"ABX9TyOyTwKnjDcjtOKaV551Z1sd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-BDorHY-0Z1S"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Q8TiItKe0abR"},"source":["# Setup Iniziale\n"]},{"cell_type":"markdown","metadata":{"id":"inf8757zLJBJ"},"source":["\n","\n","1.   Attivare il supporto GPU in Runtime->Change Runtime Type->Hardware Accelerator\n","2.   Check if pyCUDA è installato\n","3.   Cambia nome al notebook\n","\n"]},{"cell_type":"code","metadata":{"id":"OvPALRwa0L6d"},"source":["import pycuda\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fi_AHBnS0kht"},"source":["!pip install pycuda"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRLGYENa1FBX"},"source":["import pycuda"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eso_UlUT06Jn"},"source":["\n","\n","4.   Controlla la versione di CUDA installata\n","\n"]},{"cell_type":"code","metadata":{"id":"FZWMFCx10sPz"},"source":["!nvcc --version "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fX5vZR51Lzf"},"source":["# Esplorare la Bash"]},{"cell_type":"code","metadata":{"id":"We5N2wk61IJR"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCetqxIk1TqW"},"source":["mkdir test_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTG6-zkZ1VOO"},"source":["cd test_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHe28Pho1W7D"},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kFN9lDVO1YU8"},"source":["!touch ciao"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNCZjE7m1aiq"},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-cbIJ66Q1cLu"},"source":["rm ciao"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0LlofUYH1dnl"},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTioQ2FI1e3I"},"source":["pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFeV2rdq1gvm"},"source":["cd ..\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NKXH1k61i8q"},"source":["!gcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCfP0wuc1k34"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AjTiGKVV1qyw"},"source":["# Caratteristiche della GPU in uso\n","\n","Proviamo a capire le caratteristiche della GPU che abbiamo a disposizione.\n"]},{"cell_type":"code","metadata":{"id":"DV9AbYKP2Doo"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KI05Gn6p2LEX"},"source":["oppure si può usare il modulo pycuda, interrogando le funzioni del driver"]},{"cell_type":"code","metadata":{"id":"vhrIs7dG2Q-v"},"source":["import pycuda.driver as drv\n","drv.init()\n","drv.get_version()\n","devn=drv.Device.count()\n","print(\"N GPU \"+str(devn))\n","devices = []\n","for i in range(devn):\n","  devices.append(drv.Device(i))\n","for sp in devices:\n","  print(\"GPU name: \"+str(sp.name))\n","  print(\"Compute Capability = \"+str(sp.compute_capability()))\n","  print(\"Total Memory = \"+str(sp.total_memory()/(2.**20))+' MBytes')\n","  attr = sp.get_attributes()\n","  print(attr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LT81l35y3U7c"},"source":["oppure anche con il metodo DeviceData()"]},{"cell_type":"code","metadata":{"id":"zfC0VbBV3Z9Q"},"source":["from pycuda import autoinit\n","from pycuda.tools import DeviceData\n","specs = DeviceData()\n","print ('Max threads per block = '+str(specs.max_threads))\n","print ('Warp size            ='+str(specs.warp_size))\n","print ('Warps per MP         ='+str(specs.warps_per_mp))\n","print ('Thread Blocks per MP ='+str(specs.thread_blocks_per_mp))\n","print ('Registers            ='+str(specs.registers))\n","print ('Shared memory        ='+str(specs.shared_memory))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bpbAh6EI36BA"},"source":["# Esempio GPU in C\n","(comunque ci servirà dopo)\n","Proviamo a scrivere e compulare un programma GPU in C. Notare il comando (magic) all'inizio che serve per salvare nel workspace il contenuto della cella in un file"]},{"cell_type":"code","metadata":{"id":"Uvg9CBNr2HLg"},"source":["%%writefile VecAdd.cu\n","# include <stdio.h>\n","# include <cuda_runtime.h>\n","// CUDA Kernel\n","__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n","{\n","    int i = blockDim.x * blockIdx.x + threadIdx.x;\n","    if (i < numElements)\n","    {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n"," \n","/**\n"," * Host main routine\n"," */\n","int main(void)\n","{\n","    int numElements = 15;\n","    size_t size = numElements * sizeof(float);\n","    printf(\"[Vector addition of %d elements]\\n\", numElements);\n"," \n","    float a[numElements],b[numElements],c[numElements];\n","    float *a_gpu,*b_gpu,*c_gpu;\n"," \n","    cudaMalloc((void **)&a_gpu, size);\n","    cudaMalloc((void **)&b_gpu, size);\n","    cudaMalloc((void **)&c_gpu, size);\n"," \n","    for (int i=0;i<numElements;++i ){\n"," \n","        a[i] = i*i;\n","        b[i] = i;\n"," \n","    }\n","    // Copy the host input vectors A and B in host memory to the device input vectors in\n","    // device memory\n","    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n","    cudaMemcpy(a_gpu, a, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(b_gpu, b, size, cudaMemcpyHostToDevice);\n"," \n","    // Launch the Vector Add CUDA Kernel\n","    int threadsPerBlock = 256;\n","    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n","    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n","    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(a_gpu, b_gpu, c_gpu, numElements);\n"," \n","    // Copy the device result vector in device memory to the host result vector\n","    // in host memory.\n","    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n","    cudaMemcpy(c, c_gpu, size, cudaMemcpyDeviceToHost);\n"," \n","    for (int i=0;i<numElements;++i ){\n","        printf(\"%f \\n\",c[i]);\n","    }\n"," \n","    // Free device global memory\n","    cudaFree(a_gpu);\n","    cudaFree(b_gpu);\n","    cudaFree(c_gpu);\n"," \n","    printf(\"Done\\n\");\n","    return 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpVaQTKU4Tqu"},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVxRMNEn4U13"},"source":["!nvcc -o VecAdd VecAdd.cu\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oEZEA-hf4XFw"},"source":["!./VecAdd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mos09GvD4pkT"},"source":["# Implementazione con pycuda\n","Facciamo un primo esempio con pycuda"]},{"cell_type":"markdown","metadata":{"id":"606VLnXb42rn"},"source":["importiamo i moduli ch eci servono"]},{"cell_type":"code","metadata":{"id":"v3LBEtB_405c"},"source":["from pycuda import autoinit\n","from pycuda import gpuarray\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o7IuKf8a49h3"},"source":["definiamo i vettori a, b e c sull'host. Tutti di lunghezza 15, a con i numeri da 0..14 e b con i quadrati. c è inizializzato a 0"]},{"cell_type":"code","metadata":{"id":"EqqykG0w47CL"},"source":["aux = range(15)\n","a = np.array(aux).astype(np.float32)\n","b = (a*a).astype(np.float32)\n","c = np.zeros(len(aux)).astype(np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YU8vGpp5GZx"},"source":["Definiamo i vettori sulla GPU e copiamo dentro il contenuto dei vettori a,b e c definiti sull'host"]},{"cell_type":"code","metadata":{"id":"p4lmE35p5FuH"},"source":["a_gpu = gpuarray.to_gpu(a)\n","b_gpu = gpuarray.to_gpu(b)\n","c_gpu = gpuarray.to_gpu(c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JCmdAZpI5Stw"},"source":["un primo modo semplice per sommare i vettori e semplicemente usare il +"]},{"cell_type":"code","metadata":{"id":"wAj7IQMa5QC9"},"source":["c_gpu=a_gpu+b_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XRSDLzmI5ZsQ"},"source":["stampiamo i risultati"]},{"cell_type":"code","metadata":{"id":"zvNJem8G5Yen"},"source":["print(c_gpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDFx7jtS5crV"},"source":["c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kxaFvU5w522K"},"source":["Un secondo modo è quello di utilizzre il metodo elementwise, che applicala stessa \"Operation\" a tutti gli elementi dei vettori"]},{"cell_type":"code","metadata":{"id":"5-hes1bJ5xda"},"source":["from pycuda.elementwise import ElementwiseKernel\n","myCudaFunc = ElementwiseKernel(arguments = \"float *a, float *b, float *c\",\n","                               operation = \"c[i] = a[i]+b[i]\",\n","                               name = \"mySumK\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbGVPSAm6A2n"},"source":["myCudaFunc(a_gpu,b_gpu,c_gpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wgx02DS36MFV"},"source":["c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nenKNpM-6XcT"},"source":["Il vantaggio è che si possono definire anche operazioni piu' complesse della semplice somma, ad esempio"]},{"cell_type":"code","metadata":{"id":"tRpE-lYT6OEj"},"source":["from pycuda.elementwise import ElementwiseKernel\n","lin_comb = ElementwiseKernel(\n","        \"float a, float *x, float b, float *y, float *z\",\n","        \"z[i] = a*x[i] + b*y[i]\",\n","        \"linear_combination\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8xWF5Vj6kZe"},"source":["lin_comb(3.,a_gpu,5.,b_gpu,c_gpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dVQ8vFMl6xe0"},"source":["c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"esMo1WFj61CL"},"source":["Il terzo metodo è il piu' \"generico\". SI utilizza il mtodo SourceModule che permette di definire anche kernel piu' complessi. L'idea è che questi kernel siano comunque scritti in Cuda/C"]},{"cell_type":"code","metadata":{"id":"ABGQ11jo6yl8"},"source":["from pycuda.compiler import SourceModule\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQkDks3E7Ih8"},"source":["carichiamo il file contenente il codice in c che avevamo scritto prima (fare !ls se avete dubbi sul nome che gli avete dato)"]},{"cell_type":"code","metadata":{"id":"cQc4gZgQ7H-5"},"source":["!ls\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRwSFpDQ7Pce"},"source":["cudaCode = open(\"VecAdd.cu\",\"r\")\n","myCUDACode = cudaCode.read()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3S0l163i7Udt"},"source":["compiliamo il codice just-in-time con il metodo SourceModule()"]},{"cell_type":"code","metadata":{"id":"OHyr0Xi77Rvf"},"source":["myCode = SourceModule(myCUDACode)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IYv5w7bY8E5U"},"source":["ora il kernel (e l'host) è compilato. Importiamolo nel programma in python"]},{"cell_type":"code","metadata":{"id":"2N0GrDRH7ePy"},"source":["importedKernel = myCode.get_function(\"vectorAdd\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xc41Asfd8WAU"},"source":["definiamo la \"geometria\" della GPU che vogliamo usare"]},{"cell_type":"code","metadata":{"id":"tdOeVoo58UiP"},"source":["nThreadsPerBlock = 256\n","nBlockPerGrid = 1\n","nGridsPerBlock = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ziCtWKye8oVN"},"source":["resettiamo il vettore c_gpu (per essere sicuri sia vuoto)"]},{"cell_type":"code","metadata":{"id":"uz4UyZVO8hCd"},"source":["c_gpu.set(c)\n","c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNC6vdqg8uCV"},"source":["Il puntatore nella memoria gpu è dato dall'attributo gpudata"]},{"cell_type":"code","metadata":{"id":"laLXHktZ8lbI"},"source":["a_gpu.gpudata"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3aN9eqU81EC"},"source":["b_gpu.gpudata"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9VhJ7oT_9CWO"},"source":["lanciamo il kernel importato passandogli i puntatori dei vettori e la geometria della GPU"]},{"cell_type":"code","metadata":{"id":"y5HPzF-b9Asl"},"source":["importedKernel(a_gpu.gpudata, b_gpu.gpudata, c_gpu.gpudata, block=(nThreadsPerBlock,nBlockPerGrid,nGridsPerBlock))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GjTUdfQ9Run"},"source":["c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SrBgH3iD9vTX"},"source":["# Somma di Matrici"]},{"cell_type":"markdown","metadata":{"id":"9QaT_qwj-RgM"},"source":["Puliamo la memoria"]},{"cell_type":"code","metadata":{"id":"clV-jvyd-Jhc"},"source":["%reset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5deOJz0-l4p"},"source":["importiamo le cose che ci servono"]},{"cell_type":"code","metadata":{"id":"C3SJi0KP-Mao"},"source":["import numpy as np\n","from pycuda import gpuarray, autoinit\n","import pycuda.driver as cuda\n","from pycuda.tools import DeviceData\n","from pycuda.tools import OccupancyRecord as occupancy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwEuqu2--rNu"},"source":["inizializziamo gli array con le dimensioni appropriate"]},{"cell_type":"code","metadata":{"id":"63J6fL_x-k_J"},"source":["presCPU, presGPU = np.float32, 'float'\n","#presCPU, presGPU = np.float64, 'double'\n","a_cpu = np.random.random((512,512)).astype(presCPU)\n","b_cpu = np.random.random((512,512)).astype(presCPU)\n","c_cpu = np.zeros((512,512), dtype=presCPU)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_1m6YpI-9uG"},"source":["carichiamo matplotlib per poterlo usare nella Ipython"]},{"cell_type":"code","metadata":{"id":"lSKLYM-4-wVc"},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThFqr-3A-1YU"},"source":["from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kUF3T3n_H-7"},"source":["plt.imshow(a_cpu)\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xNmtvsw_LFQ"},"source":["plt.imshow(b_cpu)\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"muum4mUa_b_P"},"source":["copiamo gli array sulla gpu"]},{"cell_type":"code","metadata":{"id":"Ad4PsybS_Ys3"},"source":["a_gpu = gpuarray.to_gpu(a_cpu)\n","b_gpu = gpuarray.to_gpu(b_cpu)\n","c_gpu = gpuarray.to_gpu(c_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99tonycHGiwf"},"source":["c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZoIiM-pQ_xHP"},"source":["facciamo la somma prima sull'host"]},{"cell_type":"code","metadata":{"id":"hGnXkctG_jb2"},"source":["c_cpu=a_cpu+b_cpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7GyuUndc_oEM"},"source":["c_cpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k3Jt_pq5_722"},"source":["misuriamo il tempo che ci vuole sull'host per fare la somma"]},{"cell_type":"code","metadata":{"id":"PQvQzhCF_4jl"},"source":["t_cpu = %timeit -o c_cpu = a_cpu+b_cpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3nvoq-tmAJmA"},"source":["definiamo il kernel gpu per fare la somma"]},{"cell_type":"code","metadata":{"id":"9GYyUnuOADRC"},"source":["cudaKernel = '''\n","__global__ void matrixAdd(float *A, float *B, float *C)\n","{\n","    int tid_x = blockDim.x * blockIdx.x + threadIdx.x;\n","    int tid_y = blockDim.y * blockIdx.y + threadIdx.y;\n","    int tid   = gridDim.x * blockDim.x * tid_y + tid_x;\n","    C[tid] = A[tid] + B[tid];\n","}\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y3I8HDfOARbW"},"source":["ora dobbiamo compilare questo kernel e generare la funzione da usare in python"]},{"cell_type":"code","metadata":{"id":"3_1Nn480APWP"},"source":["from pycuda.compiler import SourceModule\n","myCode = SourceModule(cudaKernel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M27hvIHLAbL6"},"source":["addMatrix = myCode.get_function(\"matrixAdd\") # The output of get_function is the GPU-compiled function."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lW8Rs8NxAfP3"},"source":["type(addMatrix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-C3QrO1gAnEt"},"source":["dobbiamo decidere la geoemtria della GPU. Ad esempio si possono cercare di sfruttare tutt i threads a disposizione in un blocco. Quati thread ci sono in un blocco?"]},{"cell_type":"code","metadata":{"id":"-v9RJnsyAk1D"},"source":["dev = cuda.Device(0)\n","devdata = DeviceData(dev)\n","print (\"Using device : \"+dev.name() )\n","print(\"Max threads per block: \"+str(dev.max_threads_per_multiprocessor))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIcho9a7CXqv"},"source":["Quindi possiamo usare blocchi 32x32. Le nostre matrici sono 512x512, per cui dobbiamo usare 16x16 blocchi"]},{"cell_type":"code","metadata":{"id":"We-YWFO0BCOW"},"source":["cuBlock = (32,32,1)\n","cuGrid = (16,16,1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eIxVCPRRCyIC"},"source":["abbiamo già compilato il kernel con SourceModule. Ora abbiamo due modi per lanciarlo. O chiamiamo direttamente la funzione (come abbiamo fatto sopra per la somam di vettori)\n","```\n","kernelFunction(arg1,arg2, ... ,block=(n,m,l),grid=(r,s,t)\n","```\n","oppure usiamo la \"preparation\"\n","\n","\n","```\n","kernelFunction.prepare('ABC..') # Each letter corresponds to an input data type of the function, i = int, f = float, P = pointer, ...\n","kernelFunction.prepared_call(grid,block,arg1.gpudata,arg2,...) # When using GPU arrays, they should be passed as pointers with the attribute 'gpudata'\n","```\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"87JeKVRvDubA"},"source":["il primo metodo è, per noi\n"]},{"cell_type":"code","metadata":{"id":"sxIKEJSVCTee"},"source":["addMatrix(a_gpu,b_gpu,c_gpu,block=cuBlock,grid=cuGrid)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GlCxGDWD03n"},"source":["con la preparation è possibile midurare il tempo di esecuzione"]},{"cell_type":"code","metadata":{"id":"bjnRkFTYD0AQ"},"source":["addMatrix.prepare('PPP')\n","addMatrix.prepared_call(cuGrid,cuBlock,a_gpu.gpudata,b_gpu.gpudata,c_gpu.gpudata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Msn3Ub3RD7OT"},"source":["time2 = addMatrix.prepared_timed_call(cuGrid,cuBlock,a_gpu.gpudata,b_gpu.gpudata,c_gpu.gpudata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKJRlMtYD94Y"},"source":["time2()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2a7YxyV6EDmZ"},"source":["per controllare il risultato dobbiamo copiare il risultato dalla gpu alla cpu"]},{"cell_type":"code","metadata":{"id":"gAOMKPRuD_UI"},"source":["c = c_gpu.get()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0wSXN4fEPAP"},"source":["controlliamo il risultato per cpu e gpu"]},{"cell_type":"code","metadata":{"id":"gk205gqHEJaq"},"source":["c, c_cpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i3HptYLmETqG"},"source":["per confrontare meglio, guardiamo i plot"]},{"cell_type":"code","metadata":{"id":"bActEWJPEK30"},"source":["plt.imshow(c-c_cpu,interpolation='none')\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qn8U3GLtEXzJ"},"source":["np.sum(np.sum(np.abs(c_cpu-c)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PkLSHIS-Eeyn"},"source":["in effetti i risultati sono uguali"]},{"cell_type":"markdown","metadata":{"id":"CAmqyfhwEiuP"},"source":["# Moltiplicazione tra matrici"]},{"cell_type":"markdown","metadata":{"id":"E41bbRfVEoGP"},"source":["scriviamo un kernel per la moltiplicazione di matrici"]},{"cell_type":"code","metadata":{"id":"B1xp7ab0Elvj"},"source":["cudaKernel2 = '''\n","__global__ void matrixMul(float *A, float *B, float *C)\n","{\n","    int tid_x = blockDim.x * blockIdx.x + threadIdx.x; // Row\n","    int tid_y = blockDim.y * blockIdx.y + threadIdx.y; // Column\n","    int matrixDim = gridDim.x * blockDim.x;\n","    int tid   = matrixDim * tid_y + tid_x; // element i,j\n","    \n","    float  aux=0.0f;\n","    \n","    for ( int i=0 ; i<matrixDim ; i++ ){\n","        //          \n","        aux += A[matrixDim * tid_y + i]*B[matrixDim * i + tid_x] ;\n","    \n","    }\n","    \n","    C[tid] = aux;\n","             \n","}\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xn4rgsMrEt2O"},"source":["compiliamo e importiamo con SourceModule"]},{"cell_type":"code","metadata":{"id":"aqKdRODtEsr8"},"source":["myCode = SourceModule(cudaKernel2)\n","mulMatrix = myCode.get_function(\"matrixMul\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAxVtTOpE52H"},"source":["eseguiamolo con la stessa struttura a blocchi definite per la somma di matrici"]},{"cell_type":"code","metadata":{"id":"6jlNkU-4Eyr7"},"source":["mulMatrix(a_gpu,b_gpu,c_gpu,block=cuBlock,grid=cuGrid)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9S9tE2vHFA2n"},"source":["sulla CPU sarà invece"]},{"cell_type":"code","metadata":{"id":"dO1Iz-eQFAAx"},"source":["dotAB = np.dot(a_cpu, b_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DSKGHoYiFHOe"},"source":["vediamo il risultato è lo stesso"]},{"cell_type":"code","metadata":{"id":"NXzX6Vw7FFBY"},"source":["diff = np.abs(c_gpu.get()-dotAB)\n","np.sum(diff)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4fqh0M2FNHX"},"source":["plt.imshow(diff,interpolation='none')\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQzmJxadFmG0"},"source":["dotAB"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgpG0ryOF7ew"},"source":["c_gpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwLsGGcxF9_i"},"source":["presCPU, presGPU = np.float64, 'double'\n","a_cpu = np.random.random((512,512)).astype(presCPU)\n","b_cpu = np.random.random((512,512)).astype(presCPU)\n","c_cpu = np.zeros((512,512), dtype=presCPU)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lq3Co_HMGKFN"},"source":["a_gpu = gpuarray.to_gpu(a_cpu)\n","b_gpu = gpuarray.to_gpu(b_cpu)\n","c_gpu = gpuarray.to_gpu(c_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UfB5TgyjGPN2"},"source":["a_cpu.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqPqs-QnHow5"},"source":["cudaKernel3 = '''\n","__global__ void matrixMul64(double *A, double *B, double *C)\n","{\n","    int tid_x = blockDim.x * blockIdx.x + threadIdx.x; // Row\n","    int tid_y = blockDim.y * blockIdx.y + threadIdx.y; // Column\n","    int matrixDim = gridDim.x * blockDim.x;\n","    int tid   = matrixDim * tid_y + tid_x; // element i,j\n","    \n","    double aux = 0.0;\n","    for ( int i=0 ; i<matrixDim ; i++ ){\n","        //          \n","        aux += A[matrixDim * tid_y + i]*B[matrixDim * i + tid_x] ;\n","    \n","    }\n","    \n","    C[tid] = aux;\n","             \n","}\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ar4MYVc1HxnQ"},"source":["myCode64 = SourceModule(cudaKernel3)\n","mulMatrix64 = myCode64.get_function(\"matrixMul64\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"36vPeo1_GR5j"},"source":["mulMatrix64(a_gpu,b_gpu,c_gpu,block=cuBlock,grid=cuGrid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbtLjUyiHHnM"},"source":["dotAB = np.dot(a_cpu, b_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"opvukGlsHMHn"},"source":["c_gpu.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jky2k_VHHN6w"},"source":["dotAB.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gMHxN83HQo1"},"source":["diff = np.abs(c_gpu.get()-dotAB)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEqT8zGOHc7y"},"source":["plt.imshow(diff,interpolation='none')\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YPYvj5XIn8D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"16axfYP4JGSU"},"source":["# Ancora sulla somma di vettori"]},{"cell_type":"code","metadata":{"id":"YvlMUduWJey8"},"source":["%reset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4dmwtqcJKdDc"},"source":["Vogliamo confrontare i tempi per la somma di vettori di dimensione variabile, tra CPU e GPU"]},{"cell_type":"markdown","metadata":{"id":"2oKmh5X4Kl1l"},"source":["Iniziamo con la versione CPU"]},{"cell_type":"code","metadata":{"id":"JodMuSf4J_DV"},"source":["%matplotlib inline\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQ6DXHtjJttE"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7ERie0GJLtv"},"source":["from time import time\n","def myColorRand():\n","    return (np.random.random(),np.random.random(),np.random.random())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJx4QPRDJb8P"},"source":["dimension = [2**i for i in range(5,25) ]\n","myPrec = np.float32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ncQakFGzJeBf"},"source":["dimension"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lGTEx4AkJzPN"},"source":["nLoops = 100\n","timeCPU = []\n","for n in dimension:\n","    v1_cpu = np.random.random(n).astype(myPrec)\n","    v2_cpu = np.random.random(n).astype(myPrec)\n","    tMean = 0\n","    for i in range(nLoops):\n","        t = time() \n","        v = v1_cpu+v2_cpu\n","        t = time() - t\n","        tMean += t/nLoops\n","    timeCPU.append(tMean)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzQgJGQRJ6Qc"},"source":["plt.figure(1,figsize=(10,6))\n","plt.semilogx(dimension,timeCPU,'b-*')\n","plt.ylabel('Time (sec)')\n","plt.xlabel('N')\n","plt.xticks(dimension, dimension, rotation='vertical')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BvTrebipL898"},"source":["Proviamo a fare la versione GPU"]},{"cell_type":"markdown","metadata":{"id":"Kb4ZWZVWMCze"},"source":["Per prima cosa guardiamo la semplice somma (primo metodo)"]},{"cell_type":"code","metadata":{"id":"Bc4V9i18MOwT"},"source":["import pycuda\n","from pycuda import gpuarray"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V4nOPgm6J9Pe"},"source":["timeGPU1 = []\n","bandWidth1 = []\n","for n in dimension:\n","    v1_cpu = np.random.random(n).astype(myPrec)\n","    v2_cpu = np.random.random(n).astype(myPrec)\n","    t1Mean = 0\n","    t2Mean = 0\n","    for i in range(nLoops):\n","        t = time()\n","        vaux = gpuarray.to_gpu(v1_cpu)\n","        t = time() -t\n","        t1Mean += t/nLoops\n","    bandWidth1.append(t1Mean)\n","    v1_gpu = gpuarray.to_gpu(v1_cpu) \n","    v2_gpu = gpuarray.to_gpu(v2_cpu)\n","    for i in range(nLoops):\n","        t = time()\n","        v = v1_gpu+v2_gpu\n","        t = time() -t\n","        t2Mean += t/nLoops\n","    timeGPU1.append(t2Mean)\n","    v1_gpu.gpudata.free()\n","    v2_gpu.gpudata.free()\n","    v.gpudata.free()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyNCFBYXMLQw"},"source":["plt.figure(1,figsize=(10,6))\n","plt.semilogx(dimension,timeGPU1,'r-*',label='GPU Simple')\n","plt.semilogx(dimension,timeCPU,'b-*',label='CPU')\n","plt.ylabel('Time (sec)')\n","plt.xlabel('N')\n","plt.xticks(dimension, dimension, rotation='vertical')\n","plt.legend(loc=1,labelspacing=0.5,fancybox=True, handlelength=1.5, borderaxespad=0.25, borderpad=0.25)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ln4Xq3IGMhue"},"source":["plt.figure(1,figsize=(10,6))\n","\n","a = np.array(timeGPU1)\n","b = np.array(timeCPU)\n","plt.semilogx(dimension,b/a,'r-*',label='CPUtime/GPUtime')\n","plt.ylabel('SpeedUp x')\n","plt.xlabel('N')\n","plt.title('SpeedUP')\n","plt.xticks(dimension, dimension, rotation='vertical')\n","plt.legend(loc=1,labelspacing=0.5,fancybox=True, handlelength=1.5, borderaxespad=0.25, borderpad=0.25)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y0-4IpbYM6Dx"},"source":["proviamo anche a valutare il tempo di trasferimento su GPU"]},{"cell_type":"code","metadata":{"id":"JSYMVeSwMwCo"},"source":["plt.figure(1,figsize=(10,6))\n","sizeMB = np.array(dimension)/(2.**20)\n","plt.semilogx(sizeMB,bandWidth1,'m-+',label='GPU copy  HostToDevice')\n","plt.semilogx(sizeMB,timeGPU1,'r-*',label='GPU Simple Sum')\n","plt.ylabel('Time (sec)')\n","plt.xlabel('Memory (MB)')\n","plt.xticks(sizeMB, sizeMB, rotation='vertical')\n","plt.legend(loc=1,labelspacing=0.5,fancybox=True, handlelength=1.5, borderaxespad=0.25, borderpad=0.25)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tvkrAaJCNKv_"},"source":["proviamo ad usare elementwise (secondo metodo)"]},{"cell_type":"code","metadata":{"id":"LJNRs6S-M-fs"},"source":["from pycuda.elementwise import ElementwiseKernel\n","myCudaFunc = ElementwiseKernel(arguments = \"float *a, float *b, float *c\",\n","                               operation = \"c[i] = a[i]+b[i]\",\n","                               name = \"mySumK\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0CQXX0xNQwu"},"source":["import pycuda.driver as drv\n","start = drv.Event()\n","end = drv.Event()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpMGVIT6NXLj"},"source":["timeGPU2 = []\n","for n in dimension:\n","    v1_cpu = np.random.random(n).astype(myPrec)\n","    v2_cpu = np.random.random(n).astype(myPrec)\n","    v1_gpu = gpuarray.to_gpu(v1_cpu) \n","    v2_gpu = gpuarray.to_gpu(v2_cpu)\n","    vr_gpu  = gpuarray.to_gpu(v2_cpu)\n","    t3Mean=0\n","    for i in range(nLoops):\n","        start.record()\n","        myCudaFunc(v1_gpu,v2_gpu,vr_gpu)\n","        end.record()\n","        end.synchronize()\n","        secs = start.time_till(end)*1e-3\n","        t3Mean+=secs/nLoops\n","    timeGPU2.append(t3Mean)\n","    v1_gpu.gpudata.free()\n","    v2_gpu.gpudata.free()\n","    vr_gpu.gpudata.free()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttkKxzpUNaT7"},"source":["plt.figure(1,figsize=(10,6))\n","plt.semilogx(dimension,timeGPU1,'r-*',label='GPU Simple Sum')\n","plt.semilogx(dimension,timeGPU2,'g-*',label='GPU ElementWise Sum')\n","plt.ylabel('Time (sec)')\n","plt.xlabel('N')\n","plt.xticks(dimension, dimension, rotation='vertical')\n","plt.legend(loc=1,labelspacing=0.5,fancybox=True, handlelength=1.5, borderaxespad=0.25, borderpad=0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCjC971rNhDv"},"source":["Implementazione con SourceModule. E' possibile variare la geometria di griglia e blocchi"]},{"cell_type":"code","metadata":{"id":"eqc4XL8rN5Gm"},"source":["from pycuda.compiler import SourceModule"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fR3tDCHPNd7b"},"source":["presCPU, presGPU = np.float32, 'float'\n","cudaCode = open(\"VecAdd.cu\",\"r\")\n","cudaCode = cudaCode.read()\n","cudaCode = cudaCode.replace('float',presGPU )\n","myCode = SourceModule(cudaCode)\n","vectorAddKernel = myCode.get_function(\"vectorAdd\")\n","vectorAddKernel.prepare('PPP')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Q8aSaM9Nns_"},"source":["timeGPU3 = []\n","occupancyMesure=[]\n","for nt in [32,64,128,256,512,1024]:\n","    aux = []\n","    auxOcc = []\n","    for n in dimension:\n","        v1_cpu = np.random.random(n).astype(myPrec)\n","        v2_cpu = np.random.random(n).astype(myPrec)\n","        v1_gpu = gpuarray.to_gpu(v1_cpu) \n","        v2_gpu = gpuarray.to_gpu(v2_cpu)\n","        vr_gpu  = gpuarray.to_gpu(v2_cpu)\n","        cudaBlock = (nt,1,1) \n","        cudaGrid    = (int((n+nt-1)/nt),1,1)\n","        \n","        cudaCode = open(\"VecAdd.cu\",\"r\")\n","        cudaCode = cudaCode.read()\n","        cudaCode = cudaCode.replace('float',presGPU )\n","        downVar = ['blockDim.x','blockDim.y','blockDim.z','gridDim.x','gridDim.y','gridDim.z']\n","        upVar      = [str(cudaBlock[0]),str(cudaBlock[1]),str(cudaBlock[2]),\n","                     str(cudaGrid[0]),str(cudaGrid[1]),str(cudaGrid[2])]\n","        dicVarOptim = dict(zip(downVar,upVar))\n","        for i in downVar:\n","            cudaCode = cudaCode.replace(i,dicVarOptim[i])\n","        #print cudaCode\n","        myCode = SourceModule(cudaCode)\n","        vectorAddKernel = myCode.get_function(\"vectorAdd\")\n","        vectorAddKernel.prepare('PPP')\n","        \n","        print ('Size= '+str(n)+\" threadsPerBlock= \"+str(nt))\n","        print (str(cudaBlock)+\" \"+str(cudaGrid))\n","        t5Mean = 0\n","        for i in range(nLoops):\n","            timeAux = vectorAddKernel.prepared_timed_call(cudaGrid,cudaBlock,v1_gpu.gpudata,v2_gpu.gpudata,vr_gpu.gpudata)\n","            t5Mean += timeAux()/nLoops\n","        aux.append(t5Mean)\n","        v1_gpu.gpudata.free()\n","        v2_gpu.gpudata.free()\n","        vr_gpu.gpudata.free()\n","    timeGPU3.append(aux)\n","    occupancyMesure.append(auxOcc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MCCahWCvOI1P"},"source":["timeGPU3[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8155Pls6ObBN"},"source":["plt.figure(1,figsize=(10,6),dpi=100)\n","plt.semilogx(dimension,timeGPU1,'y-*',label='GPU Simple Sum')\n","plt.semilogx(dimension,timeGPU2,'g-*',label='GPU ElementWise Sum')\n","count = 0\n","for nt in [32,64,128,256,512,1024]:\n","    plt.semilogx(dimension,timeGPU3[count],'-*',label='GPU Kernel, block={0}'.format(nt),color=(0,1./(count+1),1))\n","    count+=1\n","plt.ylabel('Time (sec)')\n","plt.xlabel('N')\n","plt.xticks(dimension, dimension, rotation='vertical')\n","plt.legend(loc=2,labelspacing=0.5,fancybox=True, handlelength=1.5, borderaxespad=0.25, borderpad=0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGREVNCQOemI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QvSnYwjSPDkp"},"source":["# Generare il PDF del Notebook"]},{"cell_type":"code","metadata":{"id":"aL_qxW6VPHmg"},"source":["!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n","!pip install pypandoc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ny9QTs7cPZ_v"},"source":["si deve montare il proprio google drive (seguire il link per ottenere la chiave di accesso)"]},{"cell_type":"code","metadata":{"id":"3Ljc92LHPJz3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WiJfBjGBPz0n"},"source":["si deve copiare il notebook nella directory della macchina virtuale"]},{"cell_type":"code","metadata":{"id":"Ng32OyWwSsnM","executionInfo":{"status":"ok","timestamp":1604259747675,"user_tz":-60,"elapsed":923,"user":{"displayName":"Gianluca Lamanna","photoUrl":"","userId":"14260197942343570740"}}},"source":["!cp \"drive/My Drive/Colab Notebooks/handson_gpu_2020.ipynb\" ./"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3tQqJfEtU0sR"},"source":["ora si puo' convertire in pdf"]},{"cell_type":"code","metadata":{"id":"HrmcU9M4Uy48","executionInfo":{"status":"ok","timestamp":1604259696498,"user_tz":-60,"elapsed":7249,"user":{"displayName":"Gianluca Lamanna","photoUrl":"","userId":"14260197942343570740"}},"outputId":"a044d5db-c896-4dd8-b4be-f44dbee304fb","colab":{"base_uri":"https://localhost:8080/"}},"source":["!jupyter nbconvert --to PDF \"handson_gpu_2020.ipynb\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["[NbConvertApp] Converting notebook handson_gpu_2020.ipynb to PDF\n","[NbConvertApp] Writing 102045 bytes to ./notebook.tex\n","[NbConvertApp] Building PDF\n","[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n","[NbConvertApp] Running bibtex 1 time: [u'bibtex', u'./notebook']\n","[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n","[NbConvertApp] PDF successfully created\n","[NbConvertApp] Writing 76597 bytes to handson_gpu_2020.pdf\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qxNl1O0kVHLD"},"source":["scaricare il file pdf prodotto dal menu files nel pannelo di sinistra (premere il destro sul file e fare download)"]},{"cell_type":"code","metadata":{"id":"-C4opXP-U8KK"},"source":[""],"execution_count":null,"outputs":[]}]}